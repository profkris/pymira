# -*- coding: utf-8 -*-
"""
Created on Tue Feb 28 09:23:48 2017

@author: simon

Simulate injection of an agent through a vascular network
Uses flow solutions from Paul Sweeney!

"""

from pymira import spatialgraph, interstitium
import pymira.front as frontPKG
import numpy as np
import os
import pickle
import warnings
import matplotlib.pyplot as plt

def parker(t,delay):
    
    # PARKER (average arterial input function from human population)
    import numpy as np
    try:
        a1 = 0.833
        a2 = 0.336
        t1 = 0.171
        t2 = 0.364
        sigma1 = 0.055 
        sigma2 = 0.134
        alpha = 1.064
        beta = 0.166
        s = 37.772
        tau = 0.482
        tMin = (t-delay) / 60.
        r1 = (a1 / (sigma1*np.sqrt(2.*np.pi))) * np.exp(-np.square(tMin-t1)/(2.*np.square(sigma1)))
        r2 = (a2 / (sigma2*np.sqrt(2.*np.pi))) * np.exp(-np.square(tMin-t2)/(2.*np.square(sigma2)))
        wo = alpha * np.exp(-beta*tMin) / (1. + np.exp(-s*(tMin-tau)))
        conc = r1 + r2 + wo
        
        conc[tMin<0] = 0.
        conc[conc<0] = 0.
        conc[~np.isfinite(conc)] = 0.
        
    except Exception,e:
        print(e)
        import pdb
        pdb.set_trace()
        
    return conc
    
def ca1(t,delay):
    
    import numpy as np
    
    t_half = 9.02 * 60. * 60. # s (http://clincancerres.aacrjournals.org/content/10/4/1446.figures-only)
    cmax = 16.4 # ug/ml
    mol_weight = 580.237e6 # ug/mol
    dose = 100. #mg/kg
    mouse_mass = 0.025 # kg (mouse mass)
    mouse_volume = 1.8 #ml (blood volume...)
    dose_mass = dose * mouse_mass * 1000. # ug
    #dose_moles = dose_mass / mol_weight # mol
    cmax_mol = dose_mass * mouse_volume * 1e6 / mol_weight # umol
    
    return cmax_mol*np.exp(-(t-delay)/t_half)
    
def gd(t,delay):
    
    import numpy as np
    
    a1 = 2.55 # mM
    m1 = 4.8 / 60. #/s
    a2 = 1.2 # mM
    m2 = 0.06 / 60. #/s
    
    return a1*np.exp(-(t-delay)*m1) + a2*np.exp(-(t-delay)*m2)
    
def impulse(t,delay):
    
    import numpy as np
    length = 1. #s
    pos = delay
    conc = np.zeros(t.shape[0])
    conc[t>=delay] = 1.
    conc[t>(delay+length)] = 0.
    return conc
    
class ParameterSet(object):
    
    def __init__(self,dt=1.,nt=1200,pixSize=[150.,150.,150.],ktrans=0.00001,D=7e-11*1e12,feNSample=3):
        self.name = ''
        self.conc_function = None
        
        # Time
        self.dt = dt #s
        self.nt = nt
        self.max_time = self.dt*self.nt
        self.time = np.arange(0,self.max_time,self.dt)
        self.output_times = np.arange(0,self.max_time,self.dt)
        
        # Interstitium
        self.pixSize = pixSize #um
        self.dx = None
        self.dy = None
        self.dz = None
        self.dt = None
                        
        self.ktrans = ktrans #/min
        self.D = D #m2/s Gd-DTPA (https://books.google.es/books?id=6fZGf8ave3wC&pg=PA343&lpg=PA343&dq=diffusion+coefficient+of+gd-dtpa&source=bl&ots=Ceg432CWar&sig=4PuxViFn9lL7pwOAkFVGwtHRe4M&hl=en&sa=X&ved=0ahUKEwjs1O-Z-NPTAhVJShQKHa6PBKQQ6AEIODAD#v=onepage&q=diffusion%20coefficient%20of%20gd-dtpa&f=false)
        
        self.feNSample = feNSample

class InjectAgent(object):
    
    def __init__(self,paramSet=None):
        if paramSet is None:
            paramSet = ParameterSet()
            
        self.paramSet = paramSet
            
        self.dt = paramSet.dt #60. #0.1 # 60. #for CA1
        self.nt = paramSet.nt
        self.max_time = paramSet.max_time
        # For CA1---
#        self.nt = 2000
#        self.max_time = 90.*60.
#        self.dt = self.max_time  / float(self.nt)
#        self.nt = int(self.max_time / self.dt)
        #-----
        self.time = paramSet.time
        self.output_times = paramSet.output_times
        
        # To convert from (nL/min) to (um^3/s) use conversion below
        self.fluxConversion = 1e6/60.
        
        self.nodeList = None
        self.graph = None
        
        self.interstitium = interstitium.Interstitium()
        
    def vertex_flow_ordering(self,node):

        node.inFlow = 0.
        node.outFlow = 0.
        node.flow = []
        node.flow_direction = []
        node.delta_pressure = []
        node.distance = 0.
        node.is_inlet = False
        node.is_outlet = False
        
        if node.nconn==0:
            return
        
        for edge in node.edges:        
            reverse = True
            if edge.at_start_node(node.index):
                reverse = False

            pressure = edge.get_scalar('Pressure',reverse=reverse)
            flow = edge.get_scalar('Flow',reverse=reverse)
            radius = edge.get_scalar('Radii',reverse=reverse)
            
            delta_pressure = (pressure[-1]-pressure[0])
            if delta_pressure>0.:
                # Pressure increasing along vessel, towards node - inflow
                flowDir = -1
                eFlow = flow[0] #-np.abs(flow[0])
                node.inFlow += np.abs(flow[0])
            elif delta_pressure<0.:
                # Pressure decreasing along vessel, away from node - outflow
                flowDir = 1
                eFlow = flow[0] #np.abs(flow[0])
                node.outFlow += np.abs(flow[0])
            elif delta_pressure==0.:
                flowDir = 0
                eFlow = flow[0] #np.abs(flow[0])
                
            velocity = np.asarray([(f*self.fluxConversion)/(np.square(r)*np.pi) for f,r in zip(flow,radius)])
            length = np.zeros(edge.npoints)
            pts = edge.coordinates
            for i in range(1,edge.npoints):
                length[i] = np.linalg.norm(pts[i]-pts[i-1]) # Length (um)
    
            delay = np.asarray([np.sum(l/np.abs(v)) if v!=0. else 1.e6 for l,v in zip(length,velocity)]) # seconds
                
            node.flow_direction.append(flowDir)
            node.flow.append(eFlow)
            node.delta_pressure.append(delta_pressure)
            
            edge.velocity = velocity
            edge.length = length
            edge.delay = delay
            edge.concentration = np.zeros([edge.npoints,len(self.time)])

        # Sort out flow direction in edges with no pressure drop            
        if 0 in node.flow_direction:
            # Find combination that minimises inflow/outflow difference
            inFlow = [node.flow[i] for i,dir in enumerate(node.flow_direction) if dir>0]
            outFlow = [node.flow[i] for i,dir in enumerate(node.flow_direction) if dir<0]
            noPD = [node.flow[i] for i,dir in enumerate(node.flow_direction) if dir==0]
            noPDInds = [i for i,dir in enumerate(node.flow_direction) if dir==0]
            mnState = None
            mn = 1e6
            #print('{} zero pressure drop edges to fix'.format(len(noPDInds)))
            from itertools import product
            for i,state in enumerate(product([-1,1], repeat=len(noPDInds))): 
                prod = np.sum(inFlow)-np.sum(outFlow)-np.sum([v*s for (v,s) in zip(noPD,state)])
                if prod<mn:
                    mnState = state
                    mn = prod
            
            for i,ind in enumerate(noPDInds):
                node.flow_direction[ind] = mnState[i]
            node.inFlow = np.sum([node.flow[i] for i,dir in enumerate(node.flow_direction) if dir>0])
            node.outFlow = np.sum([node.flow[i] for i,dir in enumerate(node.flow_direction) if dir<0])
            
        node.is_inlet = False
        #if (node.outFlow>0.) and (node.inFlow==0.):
        if node.nconn==1 and node.outFlow>0:
            node.is_inlet = True
            
#        if node.nconn==1:
        if node.inFlow==0:
            node.inFlow = node.outFlow
        elif node.outFlow==0:
            node.outFlow = node.inFlow
            
        node.Q = np.zeros(node.nconn,dtype='float') + 0.
        for i,edge in enumerate(node.edges):
            if node.flow_direction[i]>=0:
                if node.inFlow!=0.:
                    #edge.Q = node.flow[i] / node.inFlow
                    node.Q[i] = node.flow[i] / node.inFlow
                    if node.Q[i]>1.001 and 0 in node.flow_direction:
                        import pdb
                        pdb.set_trace()
                        #pass
                else:
                    node.Q[i] = 0.
                    #edge.Q = 0.
            else:
                #edge.Q = 0.
                node.Q[i] = 0.
        
    def auc(self,edges):
        
        for edge in edges:
            auc = np.sum(edge.concentration,axis=1)*self.dt
            edge.add_scalar('AUC',auc)
            
    def add_concentration(self,edges,time,conc_time=0.):
        
        idx = (np.abs(time-conc_time)).argmin()
        #conc = np.zeros([len(edges),edges[0].concentration.shape[0]])        
        for i,edge in enumerate(edges):
            concVal = edge.concentration[:,idx]
            edge.add_scalar('Concentration_{}'.format(conc_time),concVal)
            
    def add_distance(self,edges):
        for i,edge in enumerate(edges):
            if getattr(edge,'distance',None) is not None:
                edge.add_scalar('Distance',[l+edge.distance for l in edge.length])
            else:
                edge.add_scalar('Distance',[-1.]*edge.npoints)
            
    def plot_conc(self,conc):
        plt.plot(self.time, conc)
            
    def inflow_ratio(self,nodeList):
        
        for node in nodeList:
            if node.outFlow>0.:
                r = node.inFlow / node.outFlow
            else:
                r = 0.
            node.add_scalar('Flow ratio',r)
            
    def get_concentration(self,edges):
        
        conc = np.zeros([len(edges),edges[0].concentration.shape[0]])        
        for i,edge in enumerate(edges):
            conc[i,:] = edge.concentration
            
    def reconstruct_results(self, graph, output_directory=None,recon_interstitium=True,name=None, recon_vascular=True, log=False):

        self.graph = graph
        
        if name is not None:
            output_directory = os.path.join(output_directory,name)

        import dill as pickle
        
        if recon_vascular:
            try:
                nodeFile = os.path.join(output_directory,'nodeList.dill')
                if not os.path.isfile(nodeFile):
                    print 'Generating node list...'
                    self.nodeList = self.graph.node_list()
                else:
                    with open(nodeFile ,'rb') as fo:
                        self.nodeList = pickle.load(fo)
                  
                self.save_graph(output_directory=output_directory,logConc=log)
            except Exception,e:
                print e,nodeFile
                import pdb
                pdb.set_trace()
               
        if recon_interstitium:
            print('Reconstructing interstitial results...')
            import scipy
            intObj = interstitium.Interstitium()
            interDir = os.path.join(output_directory,'interstitium_calcs')
            #interDir = r'C:\Users\simon\Dropbox\160113_paul_simulation_results\LS147T\1\impulseinterstitium_calcs'
            nadded = 0
            init = False
            if not os.path.exists(interDir):
                os.mkdir(interDir)
            if os.path.isdir(interDir):
                files = os.listdir(interDir)
                for i,f in enumerate(files):
                    try:
                        curFile = os.path.join(interDir,f)
                        data = np.load(curFile)
                        curgrid = data['grid']
                        print('Reconstructing file {} of {}: {}. Max conc: {}'.format(i+1,len(files),f,np.max(curgrid)))
                        grid_dims = data['grid_dims']
                        embedDims = data['embedDims']
                        if not init:
                            grid = curgrid
                        else:
                            grid += curgrid
                        nadded += 1
                        init = True
                        pixdim = [data['dx'],data['dy'],data['dz'],data['dt']]
                        boundingBox = data['embedDims'].flatten()
                    except Exception,e:
                        print('Error loading {}: {}'.format(curFile,e))
                #ofile = os.path.join(output_directory,'interstitium.nii')
                sm = False
                if sm:
                    medwinsize = 5
                    print('Median filtering: {}'.format(medwinsize))
                    #import pdb
                    #pdb.set_trace()
                    for j in xrange(grid.shape[0]):
                        #print j
                        grid[j] = scipy.ndimage.filters.median_filter(grid[j],size=medwinsize)
                        
                #pixdim = [data['dx'],data['dy'],data['dz'],data['dt']]
                

                from pymira import mesh
                odir = os.path.join(output_directory, 'interstitial_concentration_recon')
                if not os.path.isdir(odir):
                    os.mkdir(odir)
                #timePoints = self.output_times
                #boundingBox = data['embedDims'].flatten()
                timePoints = np.linspace(np.min(self.output_times),np.max(self.output_times),num=30)
                #timePoints = np.linspace(0.,60.,num=150)
                #tp_early = np.linspace(0,60,num=100)
                #tp_late = np.linspace(60,np.max(self.output_times),num=20)
                #tp_early = np.arange(0,1200,60) #np.linspace(0,60*10,num=20)
                #tp_late = np.linspace(1200,np.max(self.output_times),num=20)
                #timePoints = np.append(tp_early,tp_late)
                print 'Interstitial timepoints: {}'.format(timePoints)
                
                #import pdb
                #pdb.set_trace()

                for ti,tp in enumerate(timePoints): 
                    cur = grid[ti,:,:,:]
                    if True: # Smoothing
                       medwinsize = 5
                       #print('Median filtering: {}'.format(medwinsize))
                       cur = scipy.ndimage.filters.median_filter(cur,size=medwinsize)
                    if log:
                        #from numpy import seterr,isneginf
                        #seterr(divide='ignore')
                        le0 = cur<=0
                        gt0 = cur>0
                        cur[gt0] = np.log(cur[gt0])
                        #seterr(divide='warn')
                        cur[le0] = -1e30
                    m = mesh.Mesh(data=cur,boundingBox=boundingBox)
                    ofile = os.path.join(odir,'interstitial_conc_t{}.am'.format(ti))
                    print('Writing (max conc {}) {}'.format(np.max(cur),ofile))
                    m.add_parameter('Time',np.asscalar(tp))
                    m.write(ofile)
                #intObj.save_grid(output_directory,grid=grid,pixdim=pixdim,format='amira')
                print('Interstitial concentration grid written to {}'.format(output_directory))
            
    def save_graph(self,output_directory=None,remove_zeros=False,logConc=False):
         
        if self.graph is None or self.nodeList is None:
            return
          
        print('Generating edge list...')
        edges = self.graph.edges_from_node_list(self.nodeList)
            
        # Reconstruct individual inlet results
        eDir = os.path.join(output_directory,'vascular_calcs')
        #eDir = r'C:\Users\simon\Dropbox\160113_paul_simulation_results\LS147T\1\impulseedge_calcs'
        files = os.listdir(eDir)
        nfiles = len(files)
        print('Loading concentration calc results ({} files)...'.format(len(files)))
        #concImported = False
        init = False
        
        #files = ['edges_inlet530.dill']
        
        for fi,f in enumerate(files):
            print('Reading file {} of {}: {}'.format(fi+1,nfiles,f))
            with open(os.path.join(eDir,f),'rb') as fo:
                curEdges,ind = pickle.load(fo)
                
            if not init:
                nt = curEdges[0].concentration.shape[1]
                ntSrc = edges[0].concentration.shape[1]
                if nt!=ntSrc:
                    print('Fixing concentration shape...')
                    for e in edges:
                        e.concentration = np.zeros([e.npoints,nt])
                init = True

            for curEdge in curEdges:
                #concImported = True
                srcEdge = [e for e in edges if e.index==curEdge.index]
                if all([i==j for i,j in zip(srcEdge[0].concentration.shape, curEdge.concentration.shape)]):
                    cur = curEdge.concentration
                    srcEdge[0].concentration += cur
                else:
                    print 'Shapes incompatible! {} {}'.format(srcEdge[0].concentration.shape,curEdge.concentration.shape)
                    
        if logConc:
            logMin = -1e30
            for curEdge in edges:
                cur = curEdge.concentration
                gt0 = cur>0.
                lt0 = cur<=0.
                curEdge.concentration[lt0] = logMin
                curEdge.concentration[gt0] = np.log(cur[gt0])

        # Calculate AUC
        #print('Calculating AUC...')
        #self.auc(edges)
        print('Adding concentration-time data to graph')
        if False: #old version - adds multiple scalar fileds to a single graph file
            # Add concentration(t=1s) as a scalar field
            timePoints = self.output_times
            for tp in timePoints:
                self.add_concentration(edges,self.time,conc_time=tp)
            print('Calculating distance...')
            self.add_distance(edges)
        else:
        #if True: #new version - creates multiple graph files (one per timepoint). Import into Amira with load timeseries
            # Add concentration(t=1s) as a scalar field
            odir = os.path.join(output_directory,'vascular_recon')
            if not os.path.isdir(odir):
                os.mkdir(odir)
            timePoints = self.output_times
            #timePoints = np.linspace(np.min(self.output_times),np.max(self.output_times),num=30)
            #timePoints = np.linspace(np.min(self.output_times),np.max(self.output_times),num=500)
            #tp_early = np.arange(0,1200,60) #np.linspace(0,60*10,num=20)
            #tp_late = np.linspace(1200,np.max(self.output_times),num=20)
            #timePoints = np.append(tp_early,tp_late)
            #timePoints = np.linspace(0.,60.,num=150)
            #tp_early = np.linspace(0,60,num=100)
            #tp_late = np.linspace(60,np.max(self.output_times),num=20)
            #timePoints = np.append(tp_early,tp_late)
            
            print 'Vascular timepoints: {}'.format(timePoints)
            for ti,tp in enumerate(timePoints):
                mx = -1e30
                for edge in edges:
                    curConc = edge.concentration[:,ti]
                    if not logConc:
                        curConc = np.clip(curConc,0.,1e100)
                    else:
                        pass
                    curMax = np.max(curConc)
                    if curMax>mx:
                        mx = curMax
                    edge.add_scalar('Concentration',curConc)
                new_graph = self.graph.node_list_to_graph(self.nodeList)
                ofile = os.path.join(odir,'concentration_t{}.am'.format(ti))
                print('Writing {}, max conc {}'.format(ofile,mx))
                new_graph.add_parameter('Time',np.asscalar(tp))
                new_graph.write(ofile)
        
        # Not working yet!
        if remove_zeros:
            # Remove edges with AUC=0
            print('Identifying zero-concentration edges')
            edge_to_delete = [e.index for e in edges if np.all(e.get_scalar('AUC')==0.)]
            print('Deleting {} EDGES'.format(len(edge_to_delete)))
            node_to_delete = np.zeros(len(self.nodeList),dtype='int')
            ndelcount = 0
            for nInd,n in enumerate(self.nodeList):
                [n.remove_edge([eInd]) for eInd,e in enumerate(n.edges) if e.index in edge_to_delete]
                #if n.nconn==0:
                #    node_to_delete[nInd] = 1
                #    ndelcount += 1
            #print('Deleting {} NODES'.format(ndelcount))
            #self.nodeList = [n for nInd,n in enumerate(self.nodeList) if node_to_delete[nInd]==1]
        
        if False:
            print('Creating new graph...')
            new_graph = self.graph.node_list_to_graph(self.nodeList)
            if output_directory is not None:
                ofile = os.path.join(output_directory,'ct_output.am')
                print('Writing graph to file ({})...'.format(ofile))
                new_graph.write(ofile)
                print('Writing complete')
                
                #ofile = os.path.join(output_directory,'')+'ct.p'            
                #print('Saving concentration data ({})...'.format(ofile))
                #conc = self.get_concentration(edges)
                #with open(ofile, 'wb') as handle:
                #    pickle.dump(ofile, handle, protocol=pickle.HIGHEST_PROTOCOL)
    
    def inject(self, graph, output_directory=None, resume=False, parallel=True, name=None, concFunc=None, largest_inflow=False, leaky_vessels=True):

        self.graph = graph   

        import dill as pickle
        import logging
        
        if name is not None:
            output_directory = os.path.join(output_directory,name)
            if not os.path.isdir(output_directory):
                os.mkdir(output_directory)
                
        logFile = os.path.join(output_directory,'inject.log')
        runFile = os.path.join(output_directory,'running.log')
        
        if resume:
            eDir = os.path.join(output_directory,'vascular_calcs')
            if os.path.isdir(eDir):
                files = os.listdir(eDir)
                nfiles = len(files)
                inletVisited = []
                prefix = 'inlet'
                suffix = '.dill'
                for fi,f in enumerate(files):
                    try:
                        ind = int((f.replace('edges_inlet','')).replace('.dill',''))
                        inletVisited.append(ind)
                        print('Inlet previously visited: {}'.format(ind))
                    except Exception,e:
                        print('Could not load {}: {}'.format(f,e))
            else:
                inletVisited = []
        else:
            inletVisited = []
            #logging.basicConfig(filename=logFile, filemode='w', level=logging.DEBUG) # Initialise log file
            target = open(logFile, 'w') # truncate log file
            target.close()
        logging.basicConfig(filename=logFile,level=logging.DEBUG,format='%(asctime)s %(levelname)s: %(message)s')
        
        nodeFile = os.path.join(output_directory,'nodeList.dill')
        #if True:
        if not os.path.isfile(nodeFile):
            print 'Generating node list...'
            nodeList = graph.node_list()
            self.nodeList = nodeList
            print 'Calculating flow ordering...'
            for node in nodeList:
                self.vertex_flow_ordering(node)
                nconn = np.asarray([x.nconn for x in self.nodeList])
        
            sTerminal = np.where(nconn==1)[0]
            nTerminal = len(sTerminal)
            
            sInlet = [node.index for node in self.nodeList if node.is_inlet==True]# and node.flow_direction[0]>=0]
            nInlet = len(sInlet)
            total_inflow = np.abs(np.sum([self.nodeList[i].flow[0] for i in sInlet]))
            inletNodes = [self.nodeList[x] for x in sInlet]
            for inletNode in inletNodes:
                inletNode.inletQ = inletNode.flow[0] / total_inflow
                inletNode.inletDelay = 0.
            
            print('Pickling node list...')
            with open(nodeFile,'wb') as fo:
                pickle.dump(nodeList,fo)
        else:
            with open(nodeFile ,'rb') as fo:
                self.nodeList = pickle.load(fo)
            inletNodes = [n for n in self.nodeList if n.is_inlet]
           
        inletNodes = [n for n in inletNodes if n.index not in inletVisited]
        
        if largest_inflow:
            inletNodes = [inletNodes[np.argmax([n.inletQ for n in inletNodes])]]
        nInlets = len(inletNodes)
        
        # Sort from highest to lowest Q
        inletQ = np.asarray([n.inletQ for n in inletNodes])
        inds = inletQ.argsort()
        inds[:] = inds[::-1] # Reverse sort
        inletNodes = [inletNodes[ind] for ind in inds]
            
        import socket
        strtInfo = 'SIMULATION STARTED: nInlets {}, name {}, parallel {}, resume {}, largest_inflow {}, leaky_vessels {}, output_directory {}, host {}'.format(nInlets,name,parallel,resume,largest_inflow,leaky_vessels,output_directory,socket.gethostname())
        logging.info(strtInfo)
        print('Logging to {}'.format(logFile))
        print strtInfo
                
        edgeFile = os.path.join(output_directory,'edgeList.dill')
        if True:
        #if not os.path.isfile(nodeFile):
            edges = graph.edges_from_node_list(self.nodeList)
        #    with open(edgeFile,'wb') as fo:
        #        pickle.dump(edges,fo)
        else:
            with open(edgeFile ,'rb') as fo:
                edges = pickle.load(fo)
        nedge = len(edges)
            
        graphFile = os.path.join(output_directory,'graph.dill')
                
        timeFile = os.path.join(output_directory,'time.dill')
        #if not os.path.isfile(timeFile):
        if True:
            with open(timeFile,'wb') as fo:
                pickle.dump(self.time,fo)

        import pathos.multiprocessing as multiprocessing
        #import multiprocessing
        ncpu = multiprocessing.cpu_count()
        p = multiprocessing.ProcessingPool(ncpu/2)
        
        #intr = interstitium.Interstitium()
        #intr.set_grid_dimensions(graph.get_data('EdgePointCoordinates'),self.time)
        
        #argList = [[nodeFile,n.index,ca1,timeFile,output_directory,nedge,intr.grid_dims,intr.embedDims] for n in inletNodes]
#        if conc_func_name=='parker':
#            concFunc = parker
#        elif conc_func_name=='impulse':
#            concFunc = impulse
#        elif conc_func_name=='ca1':
#            concFunc = ca1
#        else:
#            concFunc = impulse
        if concFunc is None:
            concFunc = impulse
        
        log = None
        argList = [[nodeFile,n.index,concFunc,timeFile,output_directory,nedge,None,None,leaky_vessels,log] for n in inletNodes]

        if parallel:
            p.map(_worker_function,argList)
        else:
            for arg in argList:
                _worker_function(arg)

        self.save_graph(output_directory=output_directory)
        
def _worker_function(args):
    
    inletIndex = None
    runFile = None
    
    def read_runfile(runFile):
        try:
            with open(runFile,'r') as fo:
                data = fo.read()
            data = data.split('\n')
            for i,d in enumerate(data):
                data[i] = d.split(', ')
            data = [d for d in data if len(d)==4]
            return data
        except:
            return None
            
    def initialise_runfile(runFile):
        with open(runFile,'w') as fo:
            pass
    
    def add_runfile_entry(runFile,index,size,step,dur):
        try:
            data = read_runfile(runFile)
            if data is not None:
                inds = [int(d[0]) for d in data]
                if index in inds: # replace line
                    pos = inds.index(index)
                    data[pos] = [index,size,step,dur]
                else:
                    data.append([index,size,step,dur])
            else:
                data = [[index,step,dur]]
            with open(runFile,'w') as fo:
                for d in data:
                    fo.write('{}, {}, {}, {}\n'.format(d[0],d[1],d[2],d[3]))
        except:
            pass
                
    def remove_runfile_entry(runFile,index):
        data = read_runfile(runFile)
        if data is not None:
            inds = [int(d[0]) for d in data]
            if index in inds: # remove line
                pos = inds.index(index)
                del data[pos]
        with open(runFile,'w') as fo:
            for d in data:
                fo.write('{}, {}, {}, {}\n'.format(d[0],d[1],d[2],d[3]))
    
    try:
    
        import pymira.front as frontPKG
        import numpy as np
        import dill as pickle
        import sys, traceback
    
        from pymira import interstitium
    
        def scale_and_shift(conc,time,Q=1.,delay=0.):
            dt = time[1]-time[0]
            d = delay / dt
            import scipy
            cnew = Q*scipy.ndimage.interpolation.shift(conc,d)
            return cnew.clip(min=0.)
        
        Q_limit = 1e-9
        c_limit = 1e-100
        Q_limit_count = 0
        c_limit_count = 0
        
        nodeListFile,inletNodeIndex,concFunc,timeFile,odir,nedge,grid_dims,embed_dims,leaky_vessels,log = args[0],args[1],args[2],args[3],args[4],args[5],args[6],args[7],args[8],args[9]
        
        import os
        eDir = os.path.join(odir,'vascular_calcs')
        if not os.path.exists(eDir):
            os.makedirs(eDir)
        vascFile = os.path.join(eDir,'edges_inlet{}.dill'.format(inletNodeIndex))
        
        import logging
        import os
        logging.basicConfig(filename=os.path.join(odir,'inject.log'),level=logging.DEBUG,format='%(asctime)s %(levelname)s: %(message)s')
        
        runFile = os.path.join(odir,'runFile.txt')
        initialise_runfile(runFile)
        add_runfile_entry(runFile,inletNodeIndex,0,0,0.)
        
        with open(nodeListFile ,'rb') as fo:
            nodeList = pickle.load(fo)
        with open(timeFile ,'rb') as fo:
            time = pickle.load(fo)
        
        nnode = len(nodeList)
        
        inletNode = [n for n in nodeList if n.index==inletNodeIndex][0]
        inletIndex = inletNode.index
        #print('Inlet index: {}'.format(inletIndex))
        dt = time[1] - time[0]
        nt = len(time)
        max_time = time[-1]
        info = 'STARTING inlet {} simulation: concFunc {}, inlet_Q {}, dt {}, nt {}, max_time {}, Q_limit {}, c_limit {}'.format(inletIndex,concFunc,inletNode.inletQ,dt,nt,max_time,Q_limit,c_limit)
        
        vedges = []
        visited = np.zeros(nnode,dtype='bool') # []
        visited_edges = np.zeros(nedge,dtype='bool')
        edgesOut = []
        curNode = inletNode
        
        #leaky_vessels = True
        ignore_delay = False
        if leaky_vessels:
            intDir = os.path.join(odir,'interstitium_calcs')
            if not os.path.exists(intDir):
                os.makedirs(intDir)
            intFile = os.path.join(intDir ,'interstitium_inlet{}.npz'.format(inletNodeIndex))            
            
            intr = interstitium.Interstitium()
            nodeCoords = np.asarray([n.coords for n in nodeList])
            intr.set_grid_dimensions(nodeCoords,time,grid_dims=grid_dims,embed_dims=embed_dims)
            grid = np.zeros(intr.grid_dims,dtype='float')
            info += ', Ktrans {}, D {}, dr {}, nr {}, embed dims {}, grid_dims {}'.format(intr.ktrans,intr.D,intr.dr,intr.nr,intr.embedDims,intr.grid_dims)
            
        #import socket
        #info += ', host {}'.format(socket.gethostname())
        
        logging.info(info)
        print info
        
        #print('Inlet node info: delay: {} Q:{}'.format(inletNode.inletDelay,inletNode.inletQ))
        front = frontPKG.Front([inletNode],delay=inletNode.inletDelay,Q=inletNode.inletQ,distance=inletNode.distance,conc=None,verbose=False)
        
        # START WALK...
        endloop = False
        count = 0
        nStepMax = 200 #1e3
        
        # Stats
        max_n_front = 0
        import time as timeMod
        t0 = timeMod.time()
        
        exitStr = 'undefined'
    
        while endloop is False:
            count += 1
            if count>=nStepMax:
                endloop = True

            dur = timeMod.time() - t0                
            add_runfile_entry(runFile,inletNodeIndex,front.front_size,count,dur)
            
            if len(front.Q)>0:
                mnQ = np.min(front.Q[0:front.front_size])
                mxQ = np.max(front.Q[0:front.front_size])
                mxC = np.max(front.conc[0:front.front_size])
                #print('Inlet: {}., iteration: {}, front size: {},maxQ: {}, c_v(max): {}, c_i(max) {}'.format(inletNodeIndex,count,front.front_size,mnQ,mxC,np.max(intr.grid)))
    
            if front.front_size>0 and endloop is False:
                if front.front_size>max_n_front:
                    max_n_front = front.front_size
                (current_nodes,delay,Q,distance,concIn) = front.get_current_front()
    
                for n,curNode in enumerate(current_nodes):
                    #print('Q: {}'.format(curNode.Q))
                    #print('dP: {}'.format(curNode.delta_pressure))
                    
                    if not visited[curNode.index]:
                        visited[curNode.index] = True
                    
                    res = [(nodeList[nodeIndex],curNode.edges[i],curNode.Q[i]) for i,nodeIndex in enumerate(curNode.connecting_node) if curNode.Q[i]>0.]
                    #Q_limit_count += len([i for i,nodeIndex in enumerate(curNode.connecting_node) if curNode.Q[i]>0.]
                        
                    if len(res)>0:
                        
                        # Select qualifying branches
                        next_nodes = [r[0] for r in res if r[2]!=0.]
                        via_edges = [r[1] for r in res if r[2]!=0.]
                        edge_Q = [r[2] for r in res if r[2]!=0.]
                        
                        delay_from = []
                        Q_from = []
                        distance_from = []
                        conc_from = [] # np.empty(0,dtype='float')
                        for ve,via_edge in enumerate(via_edges):                        
                            if via_edge not in vedges:
                                vedges.append(via_edge)
                            if not visited_edges[via_edge.index]:
                                visited_edges[via_edge.index] = True
                                edgesOut.append(via_edge)
                                via_edge.distance = distance[n]
                            
                            if leaky_vessels:
                                try:
                                    if concIn[0] is None:
                                        conc = Q[n]*edge_Q[ve]*concFunc(time,delay[n])
                                    else:
                                        if len(concIn)==1:
                                            nxtConc = concIn[0]
                                        else:
                                            nxtConc = concIn[n]
                                        if not ignore_delay:
                                            conc = scale_and_shift(nxtConc,time,Q=Q[n]*edge_Q[ve],delay=delay[n])
                                        else:
                                            conc = nxtConc * Q[n]*edge_Q[ve]
                                        
                                    edgeInd = np.zeros(via_edge.npoints,dtype='int')
                                    c_v = np.repeat([conc],via_edge.npoints,axis=0)
                                    #import pdb
                                    #pdb.set_trace()
                                    c_v_out = intr.interstitial_diffusion(via_edge.coordinates,edgeInd,c_v,time,set_grid_dims=False,progress=False,store_results=True)
                                    grid += intr.grid
                                    #c_v_out = np.repeat([c_v_out],via_edge.npoints,axis=0)
                                    via_edge.concentration = c_v_out
                                except:
                                    raise
                                    
                            else:
                                try:
                                    conc = Q[n]*edge_Q[ve]*concFunc(time,delay[n])
                                    via_edge.concentration = np.repeat([conc],via_edge.npoints,axis=0)
                                except:
                                    raise  
                                                    
                            delay_from.append(np.sum(via_edge.delay)+delay[n])
                            Q_from.append(Q[n]*edge_Q[ve])
                            distance_from.append(np.sum(via_edge.length)+distance[n])
                            if len(conc_from)==0:
                                conc_from = via_edge.concentration[-1,:]
                            elif len(conc_from.shape)==1 and conc_from.shape[0]!=0:
                                conc_from = conc_from[np.newaxis]
                                conc_from = np.append(conc_from,via_edge.concentration[-1,:][np.newaxis],axis=0)
                            else:
                                conc_from = np.append(conc_from,via_edge.concentration[-1,:][np.newaxis],axis=0)
                            
                        # Eliminate nodes that have a Q lower than limit
                        inds = [i for i,q in enumerate(Q_from) if q>Q_limit and np.max(conc_from[i])>c_limit]
                        Q_limit_count += len([q for q in Q_from if q<=Q_limit])
                        c_limit_count += len([c for c in conc_from if np.max(c)<=c_limit])
                        #import pdb
                        #pdb.set_trace()
                        if len(inds)>0:
                            if len(conc_from.shape)==1:
                                nxtConc = [conc_from]
                            elif len(conc_from.shape)==2:
                                nxtConc = conc_from[inds,:]
                            try:
                                front.step_front([next_nodes[i] for i in inds],
                                             delay=[delay_from[i] for i in inds],
                                             Q=[Q_from[i] for i in inds],
                                             distance=[distance_from[i] for i in inds],
                                             conc=nxtConc)
                            except Exception,err:
                                print err
                                import pdb
                                pdb.set_trace()
                        else:
                            pass
                    else:
                        pass
                maxConc = [np.max(e.concentration) for e in vedges]
                sind = np.where(maxConc<=0.)
                if sind[0].shape[0]>0:
                    print('Shapes incompatable!')
                    #import pdb
                    #pdb.set_trace()
                front.complete_step()
                
                save_every_step = False
                ss = 5
                if save_every_step and count % ss == ss-1:
                    print 'Writing vascular (inlet {}, step {}): {}'.format(inletNodeIndex,count,vascFile)
                    with open(vascFile,'wb') as fo:
                        pickle.dump((edgesOut,inletNodeIndex),fo)
                    if leaky_vessels:
                        print 'Writing interstitial (inlet {}, step {}): {}'.format(inletNodeIndex,count,intFile)                        
                        np.savez(intFile,grid=grid,grid_dims=intr.grid_dims,embedDims=intr.embedDims,dx=intr.dx,dy=intr.dy,dz=intr.dz,dt=intr.dt)
                    
            elif count>=nStepMax:
                endloop = True
                exitStr = 'step limit'
                #print('Exit step {}, inlet {}, max size {} - front size greater than maximum!'.format(inletNodeIndex,front.nstep,max_n_front))
            else:
                endloop = True
                exitStr = 'front complete'
                #print('Exit step {}, inlet {}, max size {} - front size 0'.format(inletNodeIndex,front.nstep,max_n_front))
                #logging.info('Inltet {} COMPLETE: max size {}, elapsed time {}'.format(inletIndex,max_n_step))
                
                #break
                
        elTime = timeMod.time() - t0
        exitInfoStr = 'COMPLETED inlet {} ({}): nstep {}, max size {}, end size {}, inlet Q {}, Q_limit {}, Q_limit_count {}, c_limit_count {}, elapsed time {}'.format(inletIndex,exitStr,front.nstep,max_n_front,front.front_size,inletNode.inletQ,Q_limit,Q_limit_count,c_limit_count,elTime)
        logging.info(exitInfoStr)
        print exitInfoStr

        with open(vascFile,'wb') as fo:
            pickle.dump((edgesOut,inletNodeIndex),fo)
            
        if leaky_vessels:   
            np.savez(intFile,grid=grid,grid_dims=intr.grid_dims,embedDims=intr.embedDims,dx=intr.dx,dy=intr.dy,dz=intr.dz,dt=intr.dt)
            
    except:
        exc_type, exc_value, exc_traceback = sys.exc_info()
        errFmt = traceback.format_exception(exc_type, exc_value,exc_traceback)
        print 'ERROR: {}'.format(errFmt)
        logging.error('Interstitium calc ({}): {}'.format(inletIndex,errFmt))
        
        
    if runFile is not None:
        remove_runfile_entry(runFile,inletNodeIndex)

def main():         
    #dir_ = 'C:\\Users\\simon\\Dropbox\\160113_paul_simulation_results\\LS147T - Post-VDA\\1\\'
    dir_ = r'C:\Users\simon\Dropbox\160113_paul_simulation_results\LS147T\1'
    #dir_ = r'D:\160113_paul_simulation_results\LS147T\1'
    #dir_ = r'D:\160113_paul_simulation_results\LS147T\1'
    #dir_ = r'D:\160113_paul_simulation_results\LS147T\1'
    #dir_ = r'C:\Users\simon\Dropbox\160113_paul_simulation_results\LS147T\1\ca1'
    f = os.path.join(dir_,'spatialGraph_RIN.am')
    #dir_ = 'C:\\Users\\simon\\Dropbox\\Mesentery\\'
    #f = dir_ + 'Flow2AmiraPressure.am'

    graph = spatialgraph.SpatialGraph()
    print('Reading graph...')
    graph.read(f)
    print('Graph read')
    
    ia = InjectAgent()
    
    recon = True
    logRecon = True
    resume = True
    parallel = False
    largest_inflow = False
    leaky_vessels = True
    name = 'gd'
    concFunc = gd
 
    if recon:
        recon_vascular = False
        recon_interstitium = True
        print 'Reconstructing... Vesels: {} Interstitium {}'.format(recon_vascular,recon_interstitium)
        ia.reconstruct_results(graph,output_directory=dir_,name=name,recon_interstitium=recon_interstitium,recon_vascular=recon_vascular,log=logRecon)
    else:
        print 'Simulating...'
        try:
            ia.inject(graph,output_directory=dir_,resume=resume,parallel=parallel,name=name,concFunc=concFunc,largest_inflow=largest_inflow,leaky_vessels=leaky_vessels)
            #ia.inject(graph,output_directory=dir_,resume=resume,parallel=parallel,name=name,largest_inflow=largest_inflow,leaky_vessels=leaky_vessels)
            print('Simulation complete')
        except KeyboardInterrupt:
            print('Ctrl-C interrupt! Saving graph')
            ia.save_graph(output_directory=dir_)
        
if __name__ == "__main__":
    #import cProfile
    #cProfile.run('main()')
    main()
    #pass
